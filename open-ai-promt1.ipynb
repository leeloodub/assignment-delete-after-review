{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "# pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File: /Users/olenapleshan/Desktop/tse_takehome_dataset.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from openai import OpenAI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_FILE = \"/Users/olenapleshan/Desktop/tse_takehome_dataset.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['date', 'name', 'company_name', 'description_of_company',\n",
      "       'favourite_memory', 'favourite_city_and_why', 'favourite_food_and_why',\n",
      "       'occupation', 'description_of_job', 'experience_relevant_to_job',\n",
      "       'growth_plan'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Check out the file provided by the client to understand the data they are working with\n",
    "df = pd.read_csv(INPUT_FILE)\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     London, for its historical landmarks and diverse cultural scene. for its historical landmarks and diverse cultural scene. Additionally, London has hosted the Summer Olympics three times: in 1908, ...\n",
       "1     Paris, for its beautiful architecture for its beautiful architecture Additionally, The Eiffel Tower was supposed to be a temporary installation, intended to stand for 20 years after being construc...\n",
       "2            Tokyo, for its unique blend of traditional and modern for its unique blend of traditional and modern Additionally, It's considered one of the world's most important and powerful global cities.\n",
       "3                                New York, because of its vibrant city life and diversity. because of its vibrant city life and diversity. Additionally, It's home to the largest metropolitan zoo in the US.\n",
       "4     Paris, for its beautiful architecture for its beautiful architecture Additionally, Paris is known as the 'City of Light', originally because of its leading role during the Age of Enlightenment and...\n",
       "5                                                                     Sydney, for its stunning harbour for its stunning harbour Additionally, Sydney Harbour Bridge is the world's largest steel arch bridge.\n",
       "6                                                                      Sydney, for its stunning harbour for its stunning harbour Additionally, The Sydney Opera House design was inspired by orange segments.\n",
       "7                                                                      Sydney, for its stunning harbour for its stunning harbour Additionally, The Sydney Opera House design was inspired by orange segments.\n",
       "8     London, for its historical landmarks and diverse cultural scene. for its historical landmarks and diverse cultural scene. Additionally, London has hosted the Summer Olympics three times: in 1908, ...\n",
       "9                                New York, because of its vibrant city life and diversity. because of its vibrant city life and diversity. Additionally, It's home to the largest metropolitan zoo in the US.\n",
       "10                                                            Tokyo, for its unique blend of traditional and modern for its unique blend of traditional and modern Additionally, Tokyo was once known as Edo.\n",
       "11    London, for its historical landmarks and diverse cultural scene. for its historical landmarks and diverse cultural scene. Additionally, More than half of the London Underground network actually ru...\n",
       "12                                                            Tokyo, for its unique blend of traditional and modern for its unique blend of traditional and modern Additionally, Tokyo was once known as Edo.\n",
       "13                                                            Tokyo, for its unique blend of traditional and modern for its unique blend of traditional and modern Additionally, Tokyo was once known as Edo.\n",
       "14    London, for its historical landmarks and diverse cultural scene. for its historical landmarks and diverse cultural scene. Additionally, More than half of the London Underground network actually ru...\n",
       "15    New York, because of its vibrant city life and diversity. because of its vibrant city life and diversity. Additionally, More than 800 languages are spoken in New York, making it the most linguisti...\n",
       "16    London, for its historical landmarks and diverse cultural scene. for its historical landmarks and diverse cultural scene. Additionally, London has hosted the Summer Olympics three times: in 1908, ...\n",
       "17           Tokyo, for its unique blend of traditional and modern for its unique blend of traditional and modern Additionally, It's considered one of the world's most important and powerful global cities.\n",
       "18    London, for its historical landmarks and diverse cultural scene. for its historical landmarks and diverse cultural scene. Additionally, London has hosted the Summer Olympics three times: in 1908, ...\n",
       "19           Tokyo, for its unique blend of traditional and modern for its unique blend of traditional and modern Additionally, It's considered one of the world's most important and powerful global cities.\n",
       "Name: favourite_city_and_why, dtype: object"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', 200)\n",
    "df['favourite_city_and_why']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additional Recommendation 1: Data clean up, a lot of repetition that may impede model perforamce (LINK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "client = OpenAI(\n",
    "  api_key=\"sk-proj-<REDACTED>\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted file to OpenAI assitant file-GKoXUdrwYkh9dWTmd8mEDs\n"
     ]
    }
   ],
   "source": [
    "# https://platform.openai.com/docs/assistants/quickstart\n",
    "# https://platform.openai.com/docs/assistants/tools/code-interpreter\n",
    "\n",
    "file = client.files.create(\n",
    "file=open(INPUT_FILE, \"rb\"),\n",
    "purpose='assistants'\n",
    ")\n",
    "print(\"Submitted file to OpenAI assitant\", file.id)\n",
    "\n",
    "assistant = client.beta.assistants.create(\n",
    "  instructions=\"You are a analysing data on correlation between jobs some people occupy and their personal interests. Try to elaborate as much as possible on your responses.\",\n",
    "  model=\"gpt-4o\",\n",
    "  tools=[{\"type\": \"code_interpreter\"}],\n",
    "  tool_resources={\n",
    "    \"code_interpreter\": {\n",
    "      \"file_ids\": [file.id]\n",
    "    }\n",
    "  }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread = client.beta.threads.create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_message_and_run(client, thread_id, assistant_id, user_prompt, instructions):\n",
    "    message = client.beta.threads.messages.create(\n",
    "        thread_id=thread_id,\n",
    "        role=\"user\",\n",
    "        content=user_prompt\n",
    "    )\n",
    "\n",
    "    run = client.beta.threads.runs.create_and_poll(\n",
    "        thread_id=thread_id,\n",
    "        assistant_id=assistant_id,\n",
    "        instructions=instructions,\n",
    "    )\n",
    "\n",
    "    return message, run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "message, run = create_message_and_run(client, \n",
    "                                      thread.id, \n",
    "                                      assistant.id,\n",
    "                                      \"What is Tina Escobar favourite city and why?\", \n",
    "                                      \"Please use the file {file_id} to answer the question.\".format(file_id=file.id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify if the issue is reproduciable by printing messages in the thread\n",
    "# My first assumption was exceeding content window. For counting tokens - https://help.openai.com/en/articles/4936856-what-are-tokens-and-how-to-count-them\n",
    "\n",
    "def print_and_count_tokens(run, thread_id):\n",
    "  context_length = 0\n",
    "  if run.status == 'completed': \n",
    "    messages = client.beta.threads.messages.list(\n",
    "      thread_id=thread_id\n",
    "    )\n",
    "    #context_length = sum(len(message.content.split(' ') for message in messages))\n",
    "    for message in messages:\n",
    "      for content in message.content:\n",
    "        print(content.text.value)\n",
    "        context_length += len(content.text.value.split(\" \"))\n",
    "  else:\n",
    "    print(run.status)\n",
    "  print(\"approx number of tokens: \", context_length + len(user_prompt1.split(' ')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tina Escobar's favorite city is New York. She favors this city because of its vibrant city life and diversity. Additionally, it's home to the largest metropolitan zoo in the U.S.\n",
      "The file appears to be a CSV with various fields, including \"favourite_city_and_why\". We can extract Tina Escobar's favorite city and the reason from that column. Let's do that now.\n",
      "To determine what Tina Escobar's favorite city is and why, I'll need to examine the contents of the uploaded file. Let's read through the document to find this information.\n",
      "What is Tina Escobar favourite city and why?\n",
      "approx number of tokens:  104\n"
     ]
    }
   ],
   "source": [
    "print_and_count_tokens(run, thread.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verifying whether adjusting prompt and/or instructions would help achieve the desired outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upon reviewing, the information has been completely captured: \n",
      "\n",
      "Tina Escobar favors New York due to its vibrant city life and diversity. Additionally, she appreciates that it is home to the largest metropolitan zoo in the U.S. The phrase \"because of its vibrant city life and diversity\" appears twice in the data, which might explain the initial confusion.\n",
      "The information may have been accidentally repeated or truncated in the read process due to formatting or structure in the data. To better understand and resolve this, I'll take a closer look at the full content of Tina Escobar's \"favourite_city_and_why\" entry and ensure it's parsed correctly without omissions. Let's review it again.\n",
      "Why are you omitting everything after the word 'additional' in the column 'favourite_city_and_why'?\n",
      "Tina Escobar's favorite city is New York. She appreciates it because of its vibrant city life and diversity. Moreover, she mentions that it's home to the largest metropolitan zoo in the U.S.\n",
      "The file contains a list of entries, each with details including a person's favorite city and the reasons why. To find Tina Escobar's favorite city and the reason behind her choice, I'll look for the relevant entry in the data.\n",
      "To answer your question, I'll first need to read the content of the uploaded file. Let's check the file to find the information about Tina Escobar's favorite city and the reason behind her choice.\n",
      "What is Tina Escobar favourite city and why?\n",
      "approx number of tokens:  244\n"
     ]
    }
   ],
   "source": [
    "message, run = create_message_and_run(client, \n",
    "                                      thread.id, \n",
    "                                      assistant.id, \n",
    "                                      \"Why are you omitting everything after the word 'additional' in the column 'favourite_city_and_why'?\", # Only changing promt. Instructions are the same, part of the same thread\n",
    "                                      \"Please use the file {file_id} to answer the question.\".format(file_id=file.id))\n",
    "\n",
    "print_and_count_tokens(run, thread.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The complete entry for Tina Escobar's favorite city is:\n",
      "\n",
      "\"New York, because of its vibrant city life and diversity. Additionally, it's home to the largest metropolitan zoo in the U.S.\"\n",
      "\n",
      "There appear to be no omissions—just a repetition of the phrase \"because of its vibrant city life and diversity.\" The content after \"Additionally\" is also included appropriately.\n",
      "Thank you for bringing this to my attention. Let's make sure we thoroughly investigate if there's any content missing from the output after the word \"Additionally\" in the column \"favourite_city_and_why\" for Tina Escobar's entry. I'll directly access and print the entry again to ensure its completeness.\n",
      "Why are you omitting everything after the word 'additional' in the column 'favourite_city_and_why'?\n",
      "Upon reviewing, the information has been completely captured: \n",
      "\n",
      "Tina Escobar favors New York due to its vibrant city life and diversity. Additionally, she appreciates that it is home to the largest metropolitan zoo in the U.S. The phrase \"because of its vibrant city life and diversity\" appears twice in the data, which might explain the initial confusion.\n",
      "The information may have been accidentally repeated or truncated in the read process due to formatting or structure in the data. To better understand and resolve this, I'll take a closer look at the full content of Tina Escobar's \"favourite_city_and_why\" entry and ensure it's parsed correctly without omissions. Let's review it again.\n",
      "Why are you omitting everything after the word 'additional' in the column 'favourite_city_and_why'?\n",
      "Tina Escobar's favorite city is New York. She appreciates it because of its vibrant city life and diversity. Moreover, she mentions that it's home to the largest metropolitan zoo in the U.S.\n",
      "The file contains a list of entries, each with details including a person's favorite city and the reasons why. To find Tina Escobar's favorite city and the reason behind her choice, I'll look for the relevant entry in the data.\n",
      "To answer your question, I'll first need to read the content of the uploaded file. Let's check the file to find the information about Tina Escobar's favorite city and the reason behind her choice.\n",
      "What is Tina Escobar favourite city and why?\n",
      "approx number of tokens:  358\n"
     ]
    }
   ],
   "source": [
    "message, run = create_message_and_run(client, \n",
    "                                      thread.id,\n",
    "                                      assistant.id, \n",
    "                                      \"What is Tina Escobar favourite city and why?\", \n",
    "                                      \"Please use the file {file_id} to answer the question. When summarising your response, please include all additional and relevant information the user provided.\".format(file_id=file.id)) # Only changing instructions. Prompt is the same, part of the same thread\n",
    "\n",
    "print_and_count_tokens(run, thread.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sarah King's favorite city is **Tokyo**. She appreciates it for its \"unique blend of traditional and modern\" aspects. Additionally, it's noted that Tokyo was once known as Edo.\n",
      "What is Sarah King's favourite city and why?\n",
      "The omission is likely due to an error in processing or a misunderstanding of the user's request. I have now shown the complete reason provided in the 'favourite_city_and_why' column for Tina Escobar. \n",
      "\n",
      "Here is the full response: Tina Escobar's favorite city is **New York** because of its \"vibrant city life and diversity.\" Additionally, it's home to the largest metropolitan zoo in the US. There was no further information omitted after the word \"Additional\" in her answer.\n",
      "Why are you omitting everything after the word 'additional' in the column 'favourite_city_and_why'?\n",
      "Tina Escobar's favorite city is **New York** because of its \"vibrant city life and diversity.\" Additionally, it's home to the largest metropolitan zoo in the US.\n",
      "It appears there was an omission in the displayed data for Tina Escobar's favorite city and its corresponding reason. My previous response was based on the visible portion of the CSV data. Let's check again and ensure the complete text is retrieved from the 'favourite_city_and_why' column for Tina Escobar.\n",
      "Why are you omitting everything after the word 'additional' in the column 'favourite_city_and_why'?\n",
      "Tina Escobar's favorite city is **New York**. She likes it because of its \"vibrant city life and opportunities.\"\n",
      "The file appears to be a CSV (Comma-Separated Values) format, not JSON. Let's parse the CSV file to extract the information about Tina Escobar's favorite city and the reason.\n",
      "It seems that there was an error reading the file as a JSON document. This might not be a JSON file, or the file could be improperly formatted. Let's try to open the file in a different way to better understand its contents.\n",
      "What is Tina Escobar favourite city and why?\n",
      "approx number of tokens:  319\n"
     ]
    }
   ],
   "source": [
    "user_prompt_sarah = \"What is Sarah King's favourite city and why?\"\n",
    "\n",
    "message, run = create_message_and_run(client, \n",
    "                                      thread.id, \n",
    "                                      assistant.id, \n",
    "                                      \"What is Sarah King's favourite city and why?\", \n",
    "                                      \"Please use the file {file_id} to answer the question.\".format(file_id=file.id)) # Using the old instruction but new prompt for a different person from the file\n",
    "\n",
    "print_and_count_tokens(run, thread.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation: When using instruction1 along with a prompt tailored for a new user, the behavior adapts and the desired outcome is achieved. However, this effect is probably just limited to the context of the current thread. Therefore, if the instructions are not exposed to the end-user and modified only by the Assistant's developer, the desired specificity of the outcome should just be embedded directly into the instruction when each run is initilized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verifying how to better engineer the prompt\n",
    "Creating a new thread to ensure the results from previous thread do not get mixed in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread2 = client.beta.threads.create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tina Escobar's favorite city is New York. She mentioned the following reasons for her preference:\n",
      "\n",
      "1. The vibrant city life.\n",
      "2. Diversity.\n",
      "3. It's home to the largest metropolitan zoo in the US.\n",
      "\n",
      "These aspects contribute to her fondness for New York City.\n",
      "The uploaded file appears to be a CSV file with multiple columns, including \"favourite_city_and_why\". It likely contains information about various individuals and their favorite cities, along with reasons.\n",
      "\n",
      "To find Tina Escobar's favorite city and the reasons she mentioned, I will parse the CSV file and search for her entry. Let's proceed with that.\n",
      "To answer your question, I will first need to examine the content of the uploaded file. Let's start by opening the file and inspecting its content.\n",
      "What is Tina Escobar favourite city? Please provide all reasons she mentioned.\n",
      "approx number of tokens:  138\n"
     ]
    }
   ],
   "source": [
    "user_prompt3 = \"What is Tina Escobar favourite city? Please provide all reasons she mentioned.\"\n",
    "\n",
    "message, run = create_message_and_run(client, \n",
    "                                      thread2.id, \n",
    "                                      assistant.id, \n",
    "                                      \"What is Tina Escobar favourite city? Please provide all reasons she mentioned.\", \n",
    "                                      \"Please use the file {file_id} to answer the question.\".format(file_id=file.id))\n",
    "\n",
    "print_and_count_tokens(run, thread2.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation: Previous prompt changes seemed to mostly expand on the content, so the user could use that. However, asking to \"provide all reasons XXX mentioned\" seems to force the model to scan through and summarize the column's content rather then take out the first sentence. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Be more specific with the instructions as these will not depend on the verbiage of an individual user interacting with the Assistance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread3 = client.beta.threads.create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paul Vega's favourite city is London. He appreciates London for its historical landmarks and diverse cultural scene. Additionally, he notes that London has hosted the Summer Olympics three times: in 1908, 1948, and 2012.\n",
      "The extracted information seems to indicate that Paul Vega's favourite city is \"London, but it cuts off and does not include the reasons. To ensure accuracy, let's check and extract the complete reason.\n",
      "The uploaded file seems to contain details organized in a tabular format with information about multiple individuals. To identify Paul Vega's favourite city and the reasons behind it, I will need to locate Paul Vega's entry and extract the relevant information. Let me do that.\n",
      "To determine Paul Vega's favourite city and the reasons behind it, I'll first need to analyze the content of the uploaded file. Let's go through the file to find this information.\n",
      "What is Paul Vega's favourite city and why?\n",
      "approx number of tokens:  159\n"
     ]
    }
   ],
   "source": [
    "message, run = create_message_and_run(client, \n",
    "                                      thread3.id, \n",
    "                                      assistant.id, \n",
    "                                      \"What is Paul Vega's favourite city and why?\", \n",
    "                                      \"Please use the file {file_id} to answer the question. When summarising your response, please provide all reasons mentioned in the user's response.\".format(file_id=file.id))\n",
    "\n",
    "print_and_count_tokens(run, thread3.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick experiment with file search\n",
    "This may be more appropriate to recommend to the User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "  api_key=\"sk-proj-<REDACTED>\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "assistantFS = client.beta.assistants.create(\n",
    "    name=\"Financial Analyst Assistant\",\n",
    "    instructions=\"You are an HR assistant, helping identify how people's intrests are related to the companies they are employed with and positions they are applying for.\",\n",
    "    model=\"gpt-4o\",\n",
    "    tools=[{\"type\": \"file_search\"}],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed\n",
      "FileCounts(cancelled=0, completed=1, failed=0, in_progress=0, total=1)\n"
     ]
    }
   ],
   "source": [
    "# stranegly, CSV file is not supported for file search. I will convert it to JSON.\n",
    "json_data = df.to_json(orient='records')\n",
    "json_file_path = 'test-file-search.json'\n",
    "with open(json_file_path, 'w') as json_file:\n",
    "    json_file.write(json_data)\n",
    "\n",
    "vector_store = client.beta.vector_stores.create(name=\"Employee Test Data\")\n",
    "with open(\"test-file-search.json\", \"rb\") as file:\n",
    "    file_batch = client.beta.vector_stores.file_batches.upload_and_poll(\n",
    "        vector_store_id=vector_store.id, files=[file]\n",
    "    )\n",
    "    print(file_batch.status)\n",
    "    print(file_batch.file_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "assistantFS = client.beta.assistants.update(\n",
    "assistant_id=assistant.id,\n",
    "tool_resources={\"file_search\": {\"vector_store_ids\": [vector_store.id]}},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread5 = client.beta.threads.create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tina Escobar's favorite city is New York because of its vibrant city life and diversity. Additionally, it is home to the largest metropolitan zoo in the US【4:0†test-file-search.json】.\n",
      "What is Tina Escobar favourite city and why?\n",
      "approx number of tokens:  43\n"
     ]
    }
   ],
   "source": [
    "message, run = create_message_and_run(client, \n",
    "                                      thread5.id, \n",
    "                                      assistantFS.id,\n",
    "                                      \"What is Tina Escobar favourite city and why?\", \n",
    "                                      \"Use the file from Vector store to provide the most exact answer to the question\")\n",
    "\n",
    "print_and_count_tokens(run, thread5.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summery: If the client's goal is to retieve the most exact verbiage from the File, File search may be a better option as it will aim to retrieve the exacrt answers."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
