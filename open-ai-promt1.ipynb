{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "# pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File: /Users/olenapleshan/Desktop/tse_takehome_dataset.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from openai import OpenAI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_FILE = \"/Users/olenapleshan/Desktop/tse_takehome_dataset_attempt3.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['date', 'name', 'company_name', 'description_of_company',\n",
      "       'favourite_memory', 'favourite_city_and_why', 'favourite_food_and_why',\n",
      "       'occupation', 'description_of_job', 'experience_relevant_to_job',\n",
      "       'growth_plan'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Check out the file provided by the client to understand the data they are working with\n",
    "df = pd.read_csv(INPUT_FILE)\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     London, for its historical landmarks and diverse cultural scene. for its historical landmarks and diverse cultural scene. Additionally, London has hosted the Summer Olympics three times: in 1908, ...\n",
       "1     Paris, for its beautiful architecture for its beautiful architecture Additionally, The Eiffel Tower was supposed to be a temporary installation, intended to stand for 20 years after being construc...\n",
       "2            Tokyo, for its unique blend of traditional and modern for its unique blend of traditional and modern Additionally, It's considered one of the world's most important and powerful global cities.\n",
       "3                                New York, because of its vibrant city life and diversity. because of its vibrant city life and diversity. Additionally, It's home to the largest metropolitan zoo in the US.\n",
       "4     Paris, for its beautiful architecture for its beautiful architecture Additionally, Paris is known as the 'City of Light', originally because of its leading role during the Age of Enlightenment and...\n",
       "5                                                                     Sydney, for its stunning harbour for its stunning harbour Additionally, Sydney Harbour Bridge is the world's largest steel arch bridge.\n",
       "6                                                                      Sydney, for its stunning harbour for its stunning harbour Additionally, The Sydney Opera House design was inspired by orange segments.\n",
       "7                                                                      Sydney, for its stunning harbour for its stunning harbour Additionally, The Sydney Opera House design was inspired by orange segments.\n",
       "8     London, for its historical landmarks and diverse cultural scene. for its historical landmarks and diverse cultural scene. Additionally, London has hosted the Summer Olympics three times: in 1908, ...\n",
       "9                                New York, because of its vibrant city life and diversity. because of its vibrant city life and diversity. Additionally, It's home to the largest metropolitan zoo in the US.\n",
       "10                                                            Tokyo, for its unique blend of traditional and modern for its unique blend of traditional and modern Additionally, Tokyo was once known as Edo.\n",
       "11    London, for its historical landmarks and diverse cultural scene. for its historical landmarks and diverse cultural scene. Additionally, More than half of the London Underground network actually ru...\n",
       "12                                                            Tokyo, for its unique blend of traditional and modern for its unique blend of traditional and modern Additionally, Tokyo was once known as Edo.\n",
       "13                                                            Tokyo, for its unique blend of traditional and modern for its unique blend of traditional and modern Additionally, Tokyo was once known as Edo.\n",
       "14    London, for its historical landmarks and diverse cultural scene. for its historical landmarks and diverse cultural scene. Additionally, More than half of the London Underground network actually ru...\n",
       "15    New York, because of its vibrant city life and diversity. because of its vibrant city life and diversity. Additionally, More than 800 languages are spoken in New York, making it the most linguisti...\n",
       "16    London, for its historical landmarks and diverse cultural scene. for its historical landmarks and diverse cultural scene. Additionally, London has hosted the Summer Olympics three times: in 1908, ...\n",
       "17           Tokyo, for its unique blend of traditional and modern for its unique blend of traditional and modern Additionally, It's considered one of the world's most important and powerful global cities.\n",
       "18    London, for its historical landmarks and diverse cultural scene. for its historical landmarks and diverse cultural scene. Additionally, London has hosted the Summer Olympics three times: in 1908, ...\n",
       "19           Tokyo, for its unique blend of traditional and modern for its unique blend of traditional and modern Additionally, It's considered one of the world's most important and powerful global cities.\n",
       "Name: favourite_city_and_why, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', 200)\n",
    "df['favourite_city_and_why']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additional Recommendation 1: Data clean up, a lot of repetition that may impede model perforamce (LINK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "client = OpenAI(\n",
    "  api_key=\"sk-proj-<REDACTED>\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted file to OpenAI assitant file-FAYTCfAC6TkkKhhekYk1rM\n"
     ]
    }
   ],
   "source": [
    "# https://platform.openai.com/docs/assistants/quickstart\n",
    "# https://platform.openai.com/docs/assistants/tools/code-interpreter\n",
    "\n",
    "file = client.files.create(\n",
    "  file=open(INPUT_FILE, \"rb\"),\n",
    "  purpose='assistants'\n",
    ")\n",
    "print(\"Submitted file to OpenAI assitant\", file.id)\n",
    "\n",
    "assistant = client.beta.assistants.create(\n",
    "  instructions=\"You are a analysing data on correlation between jobs some people occupy and their personal interests. You are tasked with writing a summary of the data and providing insights on the correlation between jobs and personal interests.\",\n",
    "  model=\"gpt-4o\",\n",
    "  tools=[{\"type\": \"code_interpreter\"}],\n",
    "  tool_resources={\n",
    "    \"code_interpreter\": {\n",
    "      \"file_ids\": [file.id]\n",
    "    }\n",
    "  }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread = client.beta.threads.create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_message_and_run(client, thread_id, assistant_id, user_prompt, instructions):\n",
    "    message = client.beta.threads.messages.create(\n",
    "        thread_id=thread_id,\n",
    "        role=\"user\",\n",
    "        content=user_prompt\n",
    "    )\n",
    "\n",
    "    run = client.beta.threads.runs.create_and_poll(\n",
    "        thread_id=thread_id,\n",
    "        assistant_id=assistant_id,\n",
    "        instructions=instructions,\n",
    "    )\n",
    "\n",
    "    return message, run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "message, run = create_message_and_run(client, \n",
    "                                      thread.id, \n",
    "                                      assistant.id,\n",
    "                                      \"What is Tina Escobar favourite city and why?\", \n",
    "                                      \"Please use the file {file_id} to answer the question.\".format(file_id=file.id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify if the issue is reproduciable by printing messages in the thread\n",
    "# My first assumption was exceeding content window. For counting tokens - https://help.openai.com/en/articles/4936856-what-are-tokens-and-how-to-count-them\n",
    "\n",
    "def print_and_count_tokens(run, thread_id):\n",
    "  context_length = 0\n",
    "  if run.status == 'completed': \n",
    "    messages = client.beta.threads.messages.list(\n",
    "      thread_id=thread_id\n",
    "    )\n",
    "    #context_length = sum(len(message.content.split(' ') for message in messages))\n",
    "    for message in messages:\n",
    "      for content in message.content:\n",
    "        print(\"[\", message.role, \"]\", \": \", content.text.value)\n",
    "        context_length += len(content.text.value.split(\" \"))\n",
    "  else:\n",
    "    print(run.status)\n",
    "  print(\"approx number of tokens: \", context_length) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ assistant ] :  Tina Escobar's favorite city is New York. She likes it because of its vibrant city life and diverse cultural experiences.\n",
      "[ assistant ] :  The content of the file is in a CSV format, not JSON. Let's proceed to load it as a CSV file, then search for Tina Escobar's favorite city and the explanation behind her preference.\n",
      "[ assistant ] :  It seems there was an issue with reading the file as JSON. Let's try another approach to determine its structure and contents. I'll examine the raw file contents to understand its format.\n",
      "[ user ] :  What is Tina Escobar favourite city and why?\n",
      "approx number of tokens:  94\n"
     ]
    }
   ],
   "source": [
    "print_and_count_tokens(run, thread.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verifying whether adjusting prompt and/or instructions would help achieve the desired outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ assistant ] :  Tina Escobar's favorite city is New York because of its vibrant city life and diversity. Additionally, she appreciates that it is home to the largest metropolitan zoo in the U.S.\n",
      "[ assistant ] :  The file's content revealed that each entry in the \"favourite_city_and_why\" column might have multiple reasons detailed across multiple sentences. Let's extract and display the entire entry related to Tina Escobar's favorite city to ensure nothing is omitted.\n",
      "[ user ] :  Why are you only summarizing the first sentence in the column 'favourite_city_and_why' when answering my question?\n",
      "[ assistant ] :  Tina Escobar's favorite city is New York. She likes it because of its vibrant city life and diverse cultural experiences.\n",
      "[ assistant ] :  The content of the file is in a CSV format, not JSON. Let's proceed to load it as a CSV file, then search for Tina Escobar's favorite city and the explanation behind her preference.\n",
      "[ assistant ] :  It seems there was an issue with reading the file as JSON. Let's try another approach to determine its structure and contents. I'll examine the raw file contents to understand its format.\n",
      "[ user ] :  What is Tina Escobar favourite city and why?\n",
      "approx number of tokens:  177\n"
     ]
    }
   ],
   "source": [
    "message, run = create_message_and_run(client, \n",
    "                                      thread.id, \n",
    "                                      assistant.id, \n",
    "                                      \"Why are you omitting everything after the word 'additional' in the column 'favourite_city_and_why'?\", # Only changing promt. Instructions are the same, part of the same thread\n",
    "                                      \"Please use the file {file_id} to answer the question.\".format(file_id=file.id))\n",
    "\n",
    "print_and_count_tokens(run, thread.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ assistant ] :  I apologize for the oversight. In summarization, I mistakenly focused primarily on the initial sentence, thinking it might encapsulate the main reason concisely. It's important to recognize that even within a single explanation, repeated phrases can appear (as seen here with the repetition of \"because of its vibrant city life and diversity\"). Some segments may contain cumulative details or additional points that contribute to the overall reasoning.\n",
      "\n",
      "Thank you for pointing it out, and I will ensure to consider the full explanation in similar tasks going forward.\n",
      "[ user ] :  So, why did your summary only include the first sentence of the data, if your assumption was based on each sentence representing a different reason?\n",
      "[ assistant ] :  Tina Escobar's favorite city is New York because of its vibrant city life and diversity. Additionally, she appreciates that it is home to the largest metropolitan zoo in the U.S.\n",
      "[ assistant ] :  The file's content revealed that each entry in the \"favourite_city_and_why\" column might have multiple reasons detailed across multiple sentences. Let's extract and display the entire entry related to Tina Escobar's favorite city to ensure nothing is omitted.\n",
      "[ user ] :  Why are you only summarizing the first sentence in the column 'favourite_city_and_why' when answering my question?\n",
      "[ assistant ] :  Tina Escobar's favorite city is New York. She likes it because of its vibrant city life and diverse cultural experiences.\n",
      "[ assistant ] :  The content of the file is in a CSV format, not JSON. Let's proceed to load it as a CSV file, then search for Tina Escobar's favorite city and the explanation behind her preference.\n",
      "[ assistant ] :  It seems there was an issue with reading the file as JSON. Let's try another approach to determine its structure and contents. I'll examine the raw file contents to understand its format.\n",
      "[ user ] :  What is Tina Escobar favourite city and why?\n",
      "approx number of tokens:  288\n"
     ]
    }
   ],
   "source": [
    "message, run = create_message_and_run(client, \n",
    "                                      thread.id, \n",
    "                                      assistant.id, \n",
    "                                      \"So, why did your summary only include the first sentence of the data, if your assumption was based on each sentence representing a different reason?\", # Only changing promt. Instructions are the same, part of the same thread\n",
    "                                      \"Please use the file {file_id} to answer the question.\".format(file_id=file.id))\n",
    "\n",
    "print_and_count_tokens(run, thread.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ assistant ] :  Tina Escobar's favorite city is New York because of its vibrant city life and diversity. Additionally, she appreciates that it is home to the largest metropolitan zoo in the U.S.\n",
      "[ user ] :  What is Tina Escobar favourite city and why?\n",
      "[ assistant ] :  I apologize for the oversight. In summarization, I mistakenly focused primarily on the initial sentence, thinking it might encapsulate the main reason concisely. It's important to recognize that even within a single explanation, repeated phrases can appear (as seen here with the repetition of \"because of its vibrant city life and diversity\"). Some segments may contain cumulative details or additional points that contribute to the overall reasoning.\n",
      "\n",
      "Thank you for pointing it out, and I will ensure to consider the full explanation in similar tasks going forward.\n",
      "[ user ] :  So, why did your summary only include the first sentence of the data, if your assumption was based on each sentence representing a different reason?\n",
      "[ assistant ] :  Tina Escobar's favorite city is New York because of its vibrant city life and diversity. Additionally, she appreciates that it is home to the largest metropolitan zoo in the U.S.\n",
      "[ assistant ] :  The file's content revealed that each entry in the \"favourite_city_and_why\" column might have multiple reasons detailed across multiple sentences. Let's extract and display the entire entry related to Tina Escobar's favorite city to ensure nothing is omitted.\n",
      "[ user ] :  Why are you only summarizing the first sentence in the column 'favourite_city_and_why' when answering my question?\n",
      "[ assistant ] :  Tina Escobar's favorite city is New York. She likes it because of its vibrant city life and diverse cultural experiences.\n",
      "[ assistant ] :  The content of the file is in a CSV format, not JSON. Let's proceed to load it as a CSV file, then search for Tina Escobar's favorite city and the explanation behind her preference.\n",
      "[ assistant ] :  It seems there was an issue with reading the file as JSON. Let's try another approach to determine its structure and contents. I'll examine the raw file contents to understand its format.\n",
      "[ user ] :  What is Tina Escobar favourite city and why?\n",
      "approx number of tokens:  326\n"
     ]
    }
   ],
   "source": [
    "message, run = create_message_and_run(client, \n",
    "                                      thread.id,\n",
    "                                      assistant.id, \n",
    "                                      \"What is Tina Escobar favourite city and why?\", \n",
    "                                      \"Please use the file {file_id} to answer the question. In your summary of the response, please incorporate the entirety of the response (all reasons) provided.\".format(file_id=file.id)) # Only changing instructions. Prompt is the same, part of the same thread\n",
    "\n",
    "print_and_count_tokens(run, thread.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ assistant ] :  Sarah King's favorite city is Tokyo because of its unique blend of traditional and modern elements. Additionally, she finds it interesting that Tokyo was once known as Edo.\n",
      "[ user ] :  What is Sarah King's favourite city and why?\n",
      "[ assistant ] :  Tina Escobar's favorite city is New York because of its vibrant city life and diversity. Additionally, she appreciates that it is home to the largest metropolitan zoo in the U.S.\n",
      "[ user ] :  What is Tina Escobar favourite city and why?\n",
      "[ assistant ] :  I apologize for the oversight. In summarization, I mistakenly focused primarily on the initial sentence, thinking it might encapsulate the main reason concisely. It's important to recognize that even within a single explanation, repeated phrases can appear (as seen here with the repetition of \"because of its vibrant city life and diversity\"). Some segments may contain cumulative details or additional points that contribute to the overall reasoning.\n",
      "\n",
      "Thank you for pointing it out, and I will ensure to consider the full explanation in similar tasks going forward.\n",
      "[ user ] :  So, why did your summary only include the first sentence of the data, if your assumption was based on each sentence representing a different reason?\n",
      "[ assistant ] :  Tina Escobar's favorite city is New York because of its vibrant city life and diversity. Additionally, she appreciates that it is home to the largest metropolitan zoo in the U.S.\n",
      "[ assistant ] :  The file's content revealed that each entry in the \"favourite_city_and_why\" column might have multiple reasons detailed across multiple sentences. Let's extract and display the entire entry related to Tina Escobar's favorite city to ensure nothing is omitted.\n",
      "[ user ] :  Why are you only summarizing the first sentence in the column 'favourite_city_and_why' when answering my question?\n",
      "[ assistant ] :  Tina Escobar's favorite city is New York. She likes it because of its vibrant city life and diverse cultural experiences.\n",
      "[ assistant ] :  The content of the file is in a CSV format, not JSON. Let's proceed to load it as a CSV file, then search for Tina Escobar's favorite city and the explanation behind her preference.\n",
      "[ assistant ] :  It seems there was an issue with reading the file as JSON. Let's try another approach to determine its structure and contents. I'll examine the raw file contents to understand its format.\n",
      "[ user ] :  What is Tina Escobar favourite city and why?\n",
      "approx number of tokens:  362\n"
     ]
    }
   ],
   "source": [
    "user_prompt_sarah = \"What is Sarah King's favourite city and why?\"\n",
    "\n",
    "message, run = create_message_and_run(client, \n",
    "                                      thread.id, \n",
    "                                      assistant.id, \n",
    "                                      \"What is Sarah King's favourite city and why?\", \n",
    "                                      \"Please use the file {file_id} to answer the question. In your summary of the response, please incorporate the entirety of the response (all reasons) provided.\".format(file_id=file.id)) # Using the old instruction but new prompt for a different person from the file\n",
    "\n",
    "print_and_count_tokens(run, thread.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation: When using instruction1 along with a prompt tailored for a new user, the behavior adapts and the desired outcome is achieved. However, this effect is probably just limited to the context of the current thread. Therefore, if the instructions are not exposed to the end-user and modified only by the Assistant's developer, the desired specificity of the outcome should just be embedded directly into the instruction when each run is initilized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verifying how to better engineer the prompt\n",
    "Creating a new thread to ensure the results from previous thread do not get mixed in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread2 = client.beta.threads.create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message:  Tina Escobar's favorite city is New York. The reasons she mentioned for her preference are:\n",
      "\n",
      "1. Its vibrant city life.\n",
      "2. Its diversity.\n",
      "3. It's home to the largest metropolitan zoo in the US.\n",
      "Message:  The file contains several columns including \"name\" and \"favourite_city_and_why\". I will filter the data to find Tina Escobar's entry and extract her favorite city along with the reasons she mentioned.\n",
      "Message:  The file appears to be in CSV format, with columns related to personal preferences and other information, including \"favourite_city_and_why.\" I will specifically search for information related to Tina Escobar's favorite city and the reasons mentioned for her preference. Let's find her entry in the file and extract the needed details.\n",
      "Message:  To determine Tina Escobar's favorite city and the reasons she mentioned, I will need to analyze the content of the uploaded file. I'll read through the file to find the relevant information. Let's proceed with that.\n",
      "Message:  What is Tina Escobar favourite city? Please provide all reasons she mentioned.\n",
      "approx number of tokens:  159\n"
     ]
    }
   ],
   "source": [
    "user_prompt3 = \"What is Tina Escobar favourite city? Please provide all reasons she mentioned.\"\n",
    "\n",
    "message, run = create_message_and_run(client, \n",
    "                                      thread2.id, \n",
    "                                      assistant.id, \n",
    "                                      \"What is Tina Escobar favourite city? Please provide all reasons she mentioned.\", \n",
    "                                      \"Please use the file {file_id} to answer the question.\".format(file_id=file.id))\n",
    "\n",
    "print_and_count_tokens(run, thread2.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation: Previous prompt changes seemed to mostly expand on the content, so the user could use that. However, asking to \"provide all reasons XXX mentioned\" seems to force the model to scan through and summarize the column's content rather then take out the first sentence. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Be more specific with the instructions as these will not depend on the verbiage of an individual user interacting with the Assistance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread3 = client.beta.threads.create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message:  Paul Vega's favorite city is London. He appreciates it for its historical landmarks and diverse cultural scene. Additionally, he notes that London has hosted the Summer Olympics three times: in 1908, 1948, and 2012.\n",
      "Message:  It seems there is an issue with reading the file as a JSON. The file might be in a different format. Let me inspect the file to determine its format and extract the necessary information.\n",
      "Message:  What is Paul Vega's favourite city and why?\n",
      "approx number of tokens:  77\n"
     ]
    }
   ],
   "source": [
    "message, run = create_message_and_run(client, \n",
    "                                      thread3.id, \n",
    "                                      assistant.id, \n",
    "                                      \"What is Paul Vega's favourite city and why?\", \n",
    "                                      \"Please use the file {file_id} to answer the question. When summarising your response, please provide all reasons mentioned in the user's response.\".format(file_id=file.id))\n",
    "\n",
    "print_and_count_tokens(run, thread3.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick experiment with file search\n",
    "This may be more appropriate to recommend to the User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "  api_key=\"sk-proj-<REDACTED>\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "assistantFS = client.beta.assistants.create(\n",
    "    name=\"Financial Analyst Assistant\",\n",
    "    instructions=\"You are an HR assistant, helping identify how people's intrests are related to the companies they are employed with and positions they are applying for.\",\n",
    "    model=\"gpt-4o\",\n",
    "    tools=[{\"type\": \"file_search\"}],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed\n",
      "FileCounts(cancelled=0, completed=1, failed=0, in_progress=0, total=1)\n"
     ]
    }
   ],
   "source": [
    "# stranegly, CSV file is not supported for file search. I will convert it to JSON.\n",
    "json_data = df.to_json(orient='records')\n",
    "json_file_path = 'test-file-search.json'\n",
    "with open(json_file_path, 'w') as json_file:\n",
    "    json_file.write(json_data)\n",
    "\n",
    "vector_store = client.beta.vector_stores.create(name=\"Employee Test Data\")\n",
    "with open(\"test-file-search.json\", \"rb\") as file:\n",
    "    file_batch = client.beta.vector_stores.file_batches.upload_and_poll(\n",
    "        vector_store_id=vector_store.id, files=[file]\n",
    "    )\n",
    "    print(file_batch.status)\n",
    "    print(file_batch.file_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "assistantFS = client.beta.assistants.update(\n",
    "assistant_id=assistant.id,\n",
    "tool_resources={\"file_search\": {\"vector_store_ids\": [vector_store.id]}},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread5 = client.beta.threads.create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tina Escobar's favorite city is New York because of its vibrant city life and diversity. Additionally, it is home to the largest metropolitan zoo in the US【4:0†test-file-search.json】.\n",
      "What is Tina Escobar favourite city and why?\n",
      "approx number of tokens:  43\n"
     ]
    }
   ],
   "source": [
    "message, run = create_message_and_run(client, \n",
    "                                      thread5.id, \n",
    "                                      assistantFS.id,\n",
    "                                      \"What is Tina Escobar favourite city and why?\", \n",
    "                                      \"Use the file from Vector store to provide the most exact answer to the question\")\n",
    "\n",
    "print_and_count_tokens(run, thread5.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summery: If the client's goal is to retieve the most exact verbiage from the File, File search may be a better option as it will aim to retrieve the exacrt answers."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
